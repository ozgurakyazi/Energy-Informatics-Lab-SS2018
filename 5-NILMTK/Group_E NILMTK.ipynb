{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group E Assignment 5: NILMTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load UKDALE data into memory and print out the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk import DataSet\n",
    "from nilmtk.utils import print_dict\n",
    "from nilmtk.timeframe import TimeFrame\n",
    "import pandas as pd\n",
    "\n",
    "ukdale = DataSet('./data/ukdale.h5')\n",
    "\n",
    "\n",
    "#train = DataSet('/path/redd.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Print out Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dict(ukdale.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_dict(ukdale.buildings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Print out the sub-metered appliances in each building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for build in ukdale.buildings:\n",
    "    print(\"Appliances of Building \" +str(build))\n",
    "    print(ukdale.buildings[build].elec.submeters())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec = ukdale.buildings[1].elec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Calculate the total energy consumption for building 1 in kWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec.mains().total_energy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Print out the type of power for mains and sub-meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec.mains().available_ac_types('power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elec.submeters().available_ac_types('power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Timeframed \"Fridge Freezer\" and \"Light\" Power Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdale_window = DataSet('./data/ukdale.h5')\n",
    "ukdale_window.set_window(start='2014-04-28', end='2014-04-29')\n",
    "\n",
    "fridge_meter = ukdale_window.buildings[1].elec['fridge freezer']\n",
    "light_meter = ukdale_window.buildings[1].elec['light']\n",
    "elec = ukdale_window.buildings[1].elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fridge_meter.plot()\n",
    "light_meter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Plot Overall Consumption For that time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_window = next(ukdale_window.buildings[1].elec.load())\n",
    "all_window.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_window['power'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculate and plot the energy consumption fraction for each sub-meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "energy_fraction_per_submeter = elec.submeters().energy_per_meter().transpose().fillna(0)\n",
    "del energy_fraction_per_submeter['reactive']\n",
    "active_en = energy_fraction_per_submeter['active']\n",
    "active_en_frac = active_en/active_en.sum()\n",
    "active_en_frac.plot(kind=\"bar\", figsize=(15,10), title=\"Active Energy Fraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apparent_en = energy_fraction_per_submeter['apparent']\n",
    "apparent_en_frac = apparent_en/apparent_en.sum()\n",
    "apparent_en_frac.plot(kind=\"bar\", figsize=(15,10), title=\"Apparent Energy Fraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Find appliances of the type “single-phase induction motor”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec.select_using_appliances(category='single-phase induction motor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from six import iteritems\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train = DataSet('./data/ukdale.h5')\n",
    "test = DataSet('./data/ukdale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_window(end=\"24-3-2013\")\n",
    "test.set_window(start=\"25-3-2013\")\n",
    "\n",
    "train_elec = train.buildings[3].elec\n",
    "test_elec = test.buildings[3].elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elec.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_elec.mains().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mains = train_elec.mains()\n",
    "mains_df = next(mains.load())\n",
    "mains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinatorial Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "from nilmtk.disaggregate import CombinatorialOptimisation\n",
    "from nilmtk.tests.testingtools import data_dir\n",
    "\n",
    "co = CombinatorialOptimisation()\n",
    "co.train(train_elec)\n",
    "end = time.time()\n",
    "print(\"Train runtime =\", end-start, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {}\n",
    "gt= {}\n",
    "\n",
    "for i, chunk in enumerate(test_elec.mains().load()):\n",
    "    chunk_drop_na = chunk.dropna()\n",
    "    pred[i] = co.disaggregate_chunk(chunk_drop_na)\n",
    "    gt[i]={}\n",
    "    \n",
    "    for meter in test_elec.submeters().meters:\n",
    "        # Only use the meters that we trained on (this saves time!)    \n",
    "        gt[i][meter] = next(meter.load())\n",
    "    gt[i] = pd.DataFrame({k:v.squeeze() for k,v in iteritems(gt[i])}, index=next(iter(gt[i].values())).index).dropna()\n",
    "    \n",
    "gt_overall = pd.concat(gt)\n",
    "gt_overall.index = gt_overall.index.droplevel()\n",
    "pred_overall = pd.concat(pred)\n",
    "pred_overall.index = pred_overall.index.droplevel()\n",
    "\n",
    "gt_overall = gt_overall[pred_overall.columns]\n",
    "\n",
    "gt_index_utc = gt_overall.index.tz_convert(\"UTC\")\n",
    "pred_index_utc = pred_overall.index.tz_convert(\"UTC\")\n",
    "common_index_utc = gt_index_utc.intersection(pred_index_utc)\n",
    "\n",
    "local_timezone = train.metadata['timezone']\n",
    "\n",
    "common_index_local = common_index_utc.tz_convert(local_timezone)\n",
    "\n",
    "gt_overall = gt_overall.ix[common_index_local]\n",
    "pred_overall = pred_overall.ix[common_index_local]\n",
    "\n",
    "gt_overall.head()\n",
    "\n",
    "appliance_labels = [m.label() for m in gt_overall.columns.values]\n",
    "gt_overall.columns = appliance_labels\n",
    "pred_overall.columns = appliance_labels\n",
    "\n",
    "pred_overall.head()\n",
    "\n",
    "pred_overall.head(1000).plot(label=\"Pred\")\n",
    "gt_overall.head(1000).plot(label=\"GT\")\n",
    "plt.legend()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rms_error = {}\n",
    "for appliance in gt_overall.columns:\n",
    "    rms_error[appliance] = np.sqrt(mean_squared_error(gt_overall[appliance], pred_overall[appliance]))\n",
    "    \n",
    "pd.Series(rms_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "from nilmtk.disaggregate import fhmm_exact\n",
    "fhmm = fhmm_exact.FHMM()\n",
    "\n",
    "fhmm.train(train_elec)\n",
    "end = time.time()\n",
    "print(\"Runtime =\", end-start, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {}\n",
    "gt= {}\n",
    "\n",
    "for i, chunk in enumerate(test_elec.mains().load(sample_period=60)):\n",
    "    chunk_drop_na = chunk.dropna()\n",
    "    pred[i] = fhmm.disaggregate_chunk(chunk_drop_na)\n",
    "    gt[i]={}\n",
    "    \n",
    "    for meter in test_elec.submeters().meters:\n",
    "        # Only use the meters that we trained on (this saves time!)    \n",
    "        gt[i][meter] = next(meter.load(sample_period=60))\n",
    "    gt[i] = pd.DataFrame({k:v.squeeze() for k,v in iteritems(gt[i])}, index=next(iter(gt[i].values())).index).dropna()\n",
    "    \n",
    "gt_overall = pd.concat(gt)\n",
    "gt_overall.index = gt_overall.index.droplevel()\n",
    "pred_overall = pd.concat(pred)\n",
    "pred_overall.index = pred_overall.index.droplevel()\n",
    "\n",
    "gt_overall = gt_overall[pred_overall.columns]\n",
    "\n",
    "gt_index_utc = gt_overall.index.tz_convert(\"UTC\")\n",
    "pred_index_utc = pred_overall.index.tz_convert(\"UTC\")\n",
    "common_index_utc = gt_index_utc.intersection(pred_index_utc)\n",
    "\n",
    "local_timezone = train.metadata['timezone']\n",
    "\n",
    "common_index_local = common_index_utc.tz_convert(local_timezone)\n",
    "\n",
    "gt_overall = gt_overall.ix[common_index_local]\n",
    "pred_overall = pred_overall.ix[common_index_local]\n",
    "\n",
    "gt_overall.head()\n",
    "\n",
    "appliance_labels = [m.label() for m in gt_overall.columns.values]\n",
    "gt_overall.columns = appliance_labels\n",
    "pred_overall.columns = appliance_labels\n",
    "\n",
    "pred_overall.head()\n",
    "\n",
    "pred_overall.head(1000).plot(label=\"Pred\")\n",
    "gt_overall.head(1000).plot(label=\"GT\")\n",
    "plt.legend()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rms_error = {}\n",
    "for appliance in gt_overall.columns:\n",
    "    rms_error[appliance] = np.sqrt(mean_squared_error(gt_overall[appliance], pred_overall[appliance]))\n",
    "    \n",
    "pd.Series(rms_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate F-Score of CO and FHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import time\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from six import iteritems\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams['figure.figsize'] = (13, 6)\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.disaggregate import CombinatorialOptimisation, FHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train = DataSet('./data/ukdale.h5')\n",
    "test = DataSet('./data/ukdale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_window(end=\"24-3-2013\")\n",
    "test.set_window(start=\"25-3-2013\")\n",
    "\n",
    "\n",
    "train_elec = train.buildings[3].elec\n",
    "test_elec = test.buildings[3].elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 ElecMeter(instance=5, building=3, dataset='UK-DALE', appliances=[Appliance(type='projector', instance=1)])e=1)])e=1)])"
     ]
    }
   ],
   "source": [
    "top_5_train_elec = train_elec.submeters().select_top_k(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, test_elec, sample_period, timezone):\n",
    "    pred = {}\n",
    "    gt= {}\n",
    "\n",
    "    for i, chunk in enumerate(test_elec.mains().load(sample_period=sample_period)):\n",
    "        chunk_drop_na = chunk.dropna()\n",
    "        pred[i] = clf.disaggregate_chunk(chunk_drop_na)\n",
    "        gt[i]={}\n",
    "\n",
    "        for meter in test_elec.submeters().meters:\n",
    "            # Only use the meters that we trained on (this saves time!)    \n",
    "            gt[i][meter] = next(meter.load(sample_period=sample_period))\n",
    "        gt[i] = pd.DataFrame({k:v.squeeze() for k,v in iteritems(gt[i])}, index=next(iter(gt[i].values())).index).dropna()\n",
    "        \n",
    "    # If everything can fit in memory\n",
    "    gt_overall = pd.concat(gt)\n",
    "    gt_overall.index = gt_overall.index.droplevel()\n",
    "    pred_overall = pd.concat(pred)\n",
    "    pred_overall.index = pred_overall.index.droplevel()\n",
    "\n",
    "    # Having the same order of columns\n",
    "    gt_overall = gt_overall[pred_overall.columns]\n",
    "    \n",
    "    #Intersection of index\n",
    "    gt_index_utc = gt_overall.index.tz_convert(\"UTC\")\n",
    "    pred_index_utc = pred_overall.index.tz_convert(\"UTC\")\n",
    "    common_index_utc = gt_index_utc.intersection(pred_index_utc)\n",
    "    \n",
    "    \n",
    "    common_index_local = common_index_utc.tz_convert(timezone)\n",
    "    gt_overall = gt_overall.ix[common_index_local]\n",
    "    pred_overall = pred_overall.ix[common_index_local]\n",
    "    appliance_labels = [m.label() for m in gt_overall.columns.values]\n",
    "    gt_overall.columns = appliance_labels\n",
    "    pred_overall.columns = appliance_labels\n",
    "    return gt_overall, pred_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "CO\n",
      "********************\n",
      "Training model for submeter 'ElecMeter(instance=3, building=3, dataset='UK-DALE', appliances=[Appliance(type='electric space heater', instance=1)])'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:257: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for submeter 'ElecMeter(instance=4, building=3, dataset='UK-DALE', appliances=[Appliance(type='laptop computer', instance=1)])'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:257: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for submeter 'ElecMeter(instance=2, building=3, dataset='UK-DALE', appliances=[Appliance(type='kettle', instance=1)])'\n",
      "Training model for submeter 'ElecMeter(instance=5, building=3, dataset='UK-DALE', appliances=[Appliance(type='projector', instance=1)])'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardanimaulana/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py:257: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n",
      "Estimating power demand for 'ElecMeter(instance=3, building=3, dataset='UK-DALE', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=4, building=3, dataset='UK-DALE', appliances=[Appliance(type='laptop computer', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=2, building=3, dataset='UK-DALE', appliances=[Appliance(type='kettle', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=5, building=3, dataset='UK-DALE', appliances=[Appliance(type='projector', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=3, building=3, dataset='UK-DALE', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=4, building=3, dataset='UK-DALE', appliances=[Appliance(type='laptop computer', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=2, building=3, dataset='UK-DALE', appliances=[Appliance(type='kettle', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=5, building=3, dataset='UK-DALE', appliances=[Appliance(type='projector', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=3, building=3, dataset='UK-DALE', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=4, building=3, dataset='UK-DALE', appliances=[Appliance(type='laptop computer', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=2, building=3, dataset='UK-DALE', appliances=[Appliance(type='kettle', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=5, building=3, dataset='UK-DALE', appliances=[Appliance(type='projector', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=3, building=3, dataset='UK-DALE', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=4, building=3, dataset='UK-DALE', appliances=[Appliance(type='laptop computer', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=2, building=3, dataset='UK-DALE', appliances=[Appliance(type='kettle', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=5, building=3, dataset='UK-DALE', appliances=[Appliance(type='projector', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=3, building=3, dataset='UK-DALE', appliances=[Appliance(type='electric space heater', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=4, building=3, dataset='UK-DALE', appliances=[Appliance(type='laptop computer', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=2, building=3, dataset='UK-DALE', appliances=[Appliance(type='kettle', instance=1)])'\n",
      "Estimating power demand for 'ElecMeter(instance=5, building=3, dataset='UK-DALE', appliances=[Appliance(type='projector', instance=1)])'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid info for [index] for [tz], existing_value [Europe/London] conflicts with new value [Europe/London]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2e0f4470cf63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_5_train_elec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisaggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_elec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#gt, predictions[clf_name] = predict(clf, test_elec, 120, train.metadata['timezone'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/nilmtk/disaggregate/combinatorial_optimisation.py\u001b[0m in \u001b[0;36mdisaggregate\u001b[0;34m(self, mains, output_datastore, **load_kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                     columns=cols)\n\u001b[1;32m    170\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/elec/meter{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilding_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeter_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0moutput_datastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# Copy mains data to disag output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/nilmtk/docinherit.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__module__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_parent_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverridden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/nilmtk/datastore/hdfdatastore.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mso\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcareful\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, key, value, format, append, columns, dropna, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         self._write_to_group(key, value, append=append, dropna=dropna,\n\u001b[0;32m--> 963\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def append_to_multiple(self, d, value, selector, data_columns=None,\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m_write_to_group\u001b[0;34m(self, key, value, format, index, append, complib, encoding, **kwargs)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0;31m# write the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_table\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, obj, axes, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, **kwargs)\u001b[0m\n\u001b[1;32m   3905\u001b[0m         self.create_axes(axes=axes, obj=obj, validate=append,\n\u001b[1;32m   3906\u001b[0m                          \u001b[0mmin_itemsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_itemsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3907\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m   3908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3909\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mcreate_axes\u001b[0;34m(self, axes, obj, validate, nan_rep, data_columns, min_itemsize, **kwargs)\u001b[0m\n\u001b[1;32m   3480\u001b[0m         self.index_axes = [\n\u001b[1;32m   3481\u001b[0m             \u001b[0mindex_axes_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3482\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3483\u001b[0m         ]\n\u001b[1;32m   3484\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3480\u001b[0m         self.index_axes = [\n\u001b[1;32m   3481\u001b[0m             \u001b[0mindex_axes_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3482\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3483\u001b[0m         ]\n\u001b[1;32m   3484\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nilmtk-env/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mupdate_info\u001b[0;34m(self, info)\u001b[0m\n\u001b[1;32m   1700\u001b[0m                         \u001b[0;34m\"invalid info for [%s] for [%s], existing_value [%s] \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0;34m\"conflicts with new value [%s]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                         % (self.name, key, existing_value, value))\n\u001b[0m\u001b[1;32m   1703\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mexisting_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid info for [index] for [tz], existing_value [Europe/London] conflicts with new value [Europe/London]"
     ]
    }
   ],
   "source": [
    "classifiers = {'CO':CombinatorialOptimisation(), 'FHMM':FHMM()}\n",
    "predictions = {}\n",
    "sample_period = 120\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(\"*\"*20)\n",
    "    print(clf_name)\n",
    "    print(\"*\" *20)\n",
    "    clf.train(top_5_train_elec, sample_period=sample_period)\n",
    "    output = HDFDataStore(\"./data/\"+str(clf_name)+\".h5\", 'w')\n",
    "    clf.disaggregate(test_elec.mains(), output, sample_period=120, resample=True)\n",
    "    output.close()\n",
    "    gt, predictions[clf_name] = predict(clf, test_elec, 120, train.metadata['timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disag = DataSet(\"./data/FHMM.h5\") #load FHMM prediction\n",
    "disag_elec = disag.buildings[3].elec\n",
    "\n",
    "f1 = f1_score(disag_elec, test_elec)\n",
    "f1.index = disag_elec.get_labels(f1.index)\n",
    "f1.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1score(gt, pred):\n",
    "    from nilmtk.metrics import f1_score\n",
    "    fscore = {}\n",
    "    for appliance in gt.columns:\n",
    "        fscore[appliance] = f1_score(predictions[appliance], gt[appliance])\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = {}\n",
    "\n",
    "for clf_name in classifiers.keys():\n",
    "    f1[clf_name] = f1_score(gt, predictions[clf_name])\n",
    "f1 = pd.DataFrame(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(gt, pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rms_error = {}\n",
    "    for appliance in gt.columns:\n",
    "        rms_error[appliance] = np.sqrt(mean_squared_error(gt[appliance], pred[appliance]))\n",
    "    return pd.Series(rms_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = {}\n",
    "for clf_name in classifiers.keys():\n",
    "    rmse[clf_name] = compute_rmse(gt, predictions[clf_name])\n",
    "rmse = pd.DataFrame(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nilmtk)",
   "language": "python",
   "name": "nilmtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
