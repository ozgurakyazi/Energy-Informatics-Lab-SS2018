{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Exercise: Data Preparation and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os, glob\n",
    "import re\n",
    "from datetime import datetime, date, time\n",
    "from six import iteritems\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blond(object):\n",
    "    \"\"\"\n",
    "        class blond: attributes: date, list of files\n",
    "    \"\"\"\n",
    "    _SD_centered = []\n",
    "    _SD_calibrated = []\n",
    "    \n",
    "    def __init__(self, date, day_data = {}):\n",
    "        self.date = date\n",
    "        self._day_data = day_data\n",
    "\n",
    "        \n",
    "    def list_files(self):\n",
    "        return self._day_data\n",
    "    \n",
    "    \n",
    "    def read_files(self, start_hm, end_hm):\n",
    "        \"\"\" read_files method scans the relevant folders and return a dictionary \n",
    "            with the files relevant to the timeframe (start_hm, end_hm)\n",
    "                {'clear'  : [files], \n",
    "                 'medal-1': [files],\n",
    "                 'medal-2': [files],\n",
    "                    ...\n",
    "                } \n",
    "        \"\"\"    \n",
    "    \n",
    "        \"\"\"READING CLEAR UNIT\"\"\"\n",
    "        path_to_clear = './data/clear/'\n",
    "        files_all = next(os.walk(path_to_clear))[2] \n",
    "        self._day_data['clear'] = []\n",
    "        \n",
    "        for file_name in files_all:            \n",
    "            pattern = r'(\\d{4}-\\d{2}-\\d{2}T\\d{2}-\\d{2}-\\d{2})'\n",
    "            regex_obj = re.search(pattern, file_name)\n",
    "            \n",
    "            if regex_obj is not None:\n",
    "                ts_format = regex_obj.group(1)\n",
    "                file_hm = datetime.strptime(ts_format, '%Y-%m-%dT%H-%M-%S').time()\n",
    "\n",
    "                if start_hm <= file_hm <= end_hm:\n",
    "                    self._day_data['clear'].append(h5py.File(path_to_clear + file_name,'r+'))\n",
    "                    \n",
    "                    \n",
    "        \"\"\"READING MEDAL UNITS\"\"\"\n",
    "        path_to_medals = './data/medal*/'\n",
    "        \n",
    "        for folder in glob.glob(path_to_medals):            \n",
    "            files_all = next(os.walk(folder))[2]  \n",
    "            medal_name = re.search(r'(medal-\\d+)', folder).group(1)\n",
    "            self._day_data[medal_name] = []\n",
    "            \n",
    "            for file_name in files_all:            \n",
    "                pattern = r'(\\d{4}-\\d{2}-\\d{2}T\\d{2}-\\d{2}-\\d{2})'\n",
    "                regex_obj = re.search(pattern, file_name)\n",
    "                \n",
    "                if regex_obj is not None:\n",
    "                    ts_format = regex_obj.group(1)\n",
    "                    file_hm = datetime.strptime(ts_format, '%Y-%m-%dT%H-%M-%S').time()\n",
    "                    \n",
    "                    if start_hm <= file_hm <= end_hm:\n",
    "                        self._day_data[medal_name].append(h5py.File(folder + file_name,'r+'))\n",
    "                        \n",
    "\n",
    "    def center(self, device, signal):  \n",
    "        if device+signal in self._SD_centered:\n",
    "            print(\"Signal '{}' for '{}' has been already centered.\".format(signal, device))\n",
    "            return\n",
    "        else:\n",
    "            self._SD_centered.append(device+signal)\n",
    "            data_list = self._day_data[device]\n",
    "            if device != 'clear': #NO OFFSET FOR CLEAR DEVICE\n",
    "                for i, data_file in enumerate(data_list):\n",
    "                    DC_offset = data_file[signal].attrs['removed_offset'] \n",
    "                    print(DC_offset)\n",
    "                    data_file[signal][:] = data_file[signal][:] + DC_offset\n",
    "                    self._day_data[device][i] = data_file\n",
    "\n",
    "            \n",
    "    def calibrate(self, device, signal):\n",
    "        if device+signal in self._SD_calibrated:\n",
    "            print(\"Signal '{}' for '{}' has been already calibrated.\".format(signal, device))\n",
    "            return\n",
    "        else:\n",
    "            self._SD_calibrated.append(device+signal)\n",
    "            data_list = self._day_data[device]\n",
    "            for i, data_file in enumerate(data_list):\n",
    "                factor = data_file[signal].attrs['calibration_factor']\n",
    "                print(factor)\n",
    "                data_file[signal][:] = (data_file[signal][:] * factor)\n",
    "                self._day_data[device][i] = data_file.astype()\n",
    "            \n",
    "            \n",
    "            \n",
    "    def it_read_signal(self, device, signal):\n",
    "        \"\"\"it_read_signal method \"\"\"\n",
    "        files = self._day_data[device]\n",
    "        return map(lambda f: f[signal][:], files)      \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Data Reading and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blond = Blond(date(2018,10,5))\n",
    "\n",
    "\"\"\" Define a timeframe\"\"\"\n",
    "start_hm = time(0,30) # start_hours_minutes\n",
    "end_hm   = time(1,0)\n",
    "\n",
    "\"\"\"Read MEDAL and CLEAR data \"\"\"\n",
    "blond.read_files(start_hm, end_hm)\n",
    "data={}\n",
    "\n",
    "\"\"\"Checking if files have been retrieved\"\"\"\n",
    "blond.list_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"signals acquisited by MEDAL\"\"\"\n",
    "medal_file = blond.list_files()['medal-1'][0]\n",
    "[key for key in medal_file.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"signals acquisited by CLEAR\"\"\"\n",
    "clear_file = blond.list_files()['clear'][0]\n",
    "[key for key in clear_file.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering and calibrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'medal-1'\n",
    "signal = 'current1'\n",
    "blond.center(device, signal)\n",
    "blond.calibrate(device, signal)\n",
    "it_signal = blond.it_read_signal(device, signal)\n",
    "\n",
    "\n",
    "\"\"\"Try to materialize map to numpy array - run this cell only once\"\"\"\n",
    "data[device+'_'+signal] = np.concatenate(list(it_signal))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medal-2_current1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to run dash app in jupyter:\n",
    "https://community.plot.ly/t/can-i-run-dash-app-in-jupyter/5235\n",
    "\"\"\"\n",
    "from IPython import display\n",
    "def show_app(app,  # type: dash.Dash\n",
    "             port=9999,\n",
    "             width=700,\n",
    "             height=350,\n",
    "             offline=True,\n",
    "             style=True,\n",
    "             **dash_flask_kwargs):\n",
    "    \"\"\"\n",
    "    Run the application inside a Jupyter notebook and show an iframe with it\n",
    "    :param app:\n",
    "    :param port:\n",
    "    :param width:\n",
    "    :param height:\n",
    "    :param offline:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    url = 'http://localhost:%d' % port\n",
    "    iframe = '<iframe src=\"{url}\" width={width} height={height}></iframe>'.format(url=url,\n",
    "                                                                                  width=width,\n",
    "                                                                                  height=height)\n",
    "    display.display_html(iframe, raw=True)\n",
    "    if offline:\n",
    "        app.css.config.serve_locally = True\n",
    "        app.scripts.config.serve_locally = True\n",
    "    if style:\n",
    "        external_css = [\"https://fonts.googleapis.com/css?family=Raleway:400,300,600\",\n",
    "                        \"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\",\n",
    "                        \"http://getbootstrap.com/dist/css/bootstrap.min.css\", ]\n",
    "\n",
    "        for css in external_css:\n",
    "            app.css.append_css({\"external_url\": css})\n",
    "\n",
    "        external_js = [\"https://code.jquery.com/jquery-3.2.1.min.js\",\n",
    "                       \"https://cdn.rawgit.com/plotly/dash-app-stylesheets/a3401de132a6d0b652ba11548736b1d1e80aa10d/dash-goldman-sachs-report-js.js\",\n",
    "                       \"http://getbootstrap.com/dist/js/bootstrap.min.js\"]\n",
    "\n",
    "        for js in external_js:\n",
    "            app.scripts.append_script({\"external_url\": js})\n",
    "\n",
    "    return app.run_server(debug=False,  # needs to be false in Jupyter\n",
    "                          port=port,\n",
    "                          **dash_flask_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Hello Dash'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Dash: A web application framework for Python.\n",
    "    '''),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='example-graph',\n",
    "        figure={\n",
    "            'data': [\n",
    "                {'x': [1, 2, 3], 'y': [4, 1, 2], 'type': 'line', 'name': 'SF'}\n",
    "            ],\n",
    "            'layout': {\n",
    "                'title': 'Dash Data Visualization'\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "show_app(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
