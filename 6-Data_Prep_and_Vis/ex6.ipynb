{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Exercise: Data Preparation and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os, glob\n",
    "import re\n",
    "from datetime import datetime, date, time\n",
    "from six import iteritems\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "class Blond(object):\n",
    "    \"\"\"\n",
    "        class blond: attributes: date, list of files\n",
    "    \"\"\"\n",
    "    _SD_centered = []\n",
    "    _SD_calibrated = []\n",
    "\n",
    "    def __init__(self, date, day_data = {}):\n",
    "        self.date = date\n",
    "        self._day_data = day_data\n",
    "        self.time_stamps = {}\n",
    "\n",
    "\n",
    "    def list_files(self):\n",
    "        return self._day_data\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _regex_map(pattern, strings_list):\n",
    "\n",
    "        regex_func = lambda f: re.search(pattern, f)\n",
    "        filter_list = map(regex_func, strings_list)\n",
    "        filter_list = filter(lambda x: x is not None, list(filter_list))\n",
    "        filter_list = map(lambda x: x.group(1), list(filter_list))\n",
    "        return list(filter_list)\n",
    "\n",
    "\n",
    "    def find_corresponding_file(self, the_time,all_timestamps):\n",
    "        current_ts = all_timestamps[0]\n",
    "        i=1\n",
    "        try:\n",
    "            while the_time >= current_ts:\n",
    "                current_ts = all_timestamps[i]\n",
    "                i+=1\n",
    "        except: # in case requested time is in the last index of the list, we will have a error in [i]. so this except makes the index work.\n",
    "            i+=1\n",
    "\n",
    "        return i-2\n",
    "    def _read_files_from_folder(self, files, start_ts, end_ts,path_to_files):\n",
    "        \"\"\"This method gets file in the folder w.r.t. to the timeframe start_ts - end_ts\n",
    "\n",
    "            How it works:\n",
    "            1. gets a list of files in the folder\n",
    "            2. extracts timestamps with _regex_map() method and converts it to datetime.time()\n",
    "            3. fetch the first file which fits the timeframe\n",
    "            4. add the remaining files by the filter start_timestamp <= file_timestamp <= end_timestamp\n",
    "\n",
    "        \"\"\"\n",
    "        pattern = r'(\\d{4}-\\d{2}-\\d{2}T\\d{2}-\\d{2}-\\d{2})'\n",
    "        timestamps = self._regex_map(pattern, files)\n",
    "        time_format = '%Y-%m-%dT%H-%M-%S'\n",
    "        timestamps = list(map(lambda ts: datetime.strptime(ts, time_format ).time(), timestamps))\n",
    "        timestamps.sort()\n",
    "        \"\"\" get the first file timestamp\"\"\"\n",
    "        file_index = self.find_corresponding_file(start_ts,timestamps)\n",
    "        #print(\"start file index:\"+str(file_index))\n",
    "        if file_index < 0: #no file found\n",
    "            return [],[]\n",
    "\n",
    "        \"\"\"add first file timestamp to the rest\"\"\"\n",
    "        res_timestamps = [timestamps[file_index]] + [ts for ts in timestamps if start_ts <= ts <= end_ts]\n",
    "        timestamps_filter= map(lambda ts: datetime.combine(self.date, ts).strftime(time_format), list(res_timestamps))\n",
    "\n",
    "        res_list = []\n",
    "        for ts in timestamps_filter:\n",
    "            res_list += [f for f in files if ts in f]\n",
    "\n",
    "        data = []\n",
    "        for a_file in res_list:\n",
    "            try:\n",
    "                data.append(h5py.File(path_to_files + a_file,'r+'))\n",
    "            except:\n",
    "                temp_file = h5py.File(path_to_files + a_file, 'r')\n",
    "                temp_file.close()\n",
    "                data.append(h5py.File(path_to_files + a_file,'r+'))\n",
    "\n",
    "        return data , res_timestamps\n",
    "\n",
    "\n",
    "    def read_files(self, start_ts, end_ts):\n",
    "        \"\"\" read_files() method scans the relevant folders and return a dictionary\n",
    "            with the files relevant to the timeframe (start_ts, end_ts)\n",
    "                {'clear'  : [files],\n",
    "                 'medal-1': [files],\n",
    "                 'medal-2': [files],\n",
    "                    ...\n",
    "                }\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"READING CLEAR UNIT\"\"\"\n",
    "        path_to_clear = './data/clear/'\n",
    "        files_all = next(os.walk(path_to_clear))[2]\n",
    "        self._day_data['clear'], self.time_stamps[\"clear\"] = self._read_files_from_folder(files_all, start_ts, end_ts,path_to_clear)\n",
    "        #self._day_data['clear'] = [h5py.File(path_to_clear + file_name,'r+') for file_name in target_files]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"READING MEDAL UNITS\"\"\"\n",
    "\n",
    "        path_to_medals = './data/medal*/'\n",
    "        folders_list =glob.glob(path_to_medals)\n",
    "        folders_list.sort()\n",
    "        for folder in folders_list:\n",
    "            files_all = next(os.walk(folder))[2]\n",
    "            medal_name = re.search(r'(medal-\\d+)', folder).group(1)\n",
    "            self._day_data[medal_name], self.time_stamps[medal_name] = self._read_files_from_folder(files_all, start_ts, end_ts,folder)\n",
    "            #self._day_data[medal_name] = [h5py.File(folder + file_name,'r+') for file_name in target_files]\n",
    "\n",
    "\n",
    "    \"\"\" center_inplace and calibrate inplace read file-by-file, do the corresponding operations and write back\n",
    "        good thing: we can process much more files like that and not be bounded by memory since each file is less than 3 GB\n",
    "        bad thing: we can't coerse from int to float\n",
    "        We do not use them.\n",
    "    \"\"\"\n",
    "    def center_inplace(self, device, signal):\n",
    "        if device+signal in self._SD_centered:\n",
    "            print(\"Signal '{}' for '{}' has been already centered.\".format(signal, device))\n",
    "            return\n",
    "        else:\n",
    "            self._SD_centered.append(device+signal)\n",
    "            data_list = self._day_data[device]\n",
    "            if device != 'clear': #NO OFFSET FOR CLEAR DEVICE\n",
    "                for i, data_file in enumerate(data_list):\n",
    "                    DC_offset = data_file[signal].attrs['removed_offset']\n",
    "                    #print(DC_offset)\n",
    "                    data_file[signal][:] = data_file[signal][:] + DC_offset\n",
    "                    self._day_data[device][i] = data_file\n",
    "\n",
    "\n",
    "    def calibrate_inplace(self, device, signal):\n",
    "        if device+signal in self._SD_calibrated:\n",
    "            print(\"Signal '{}' for '{}' has been already calibrated.\".format(signal, device))\n",
    "            return\n",
    "        else:\n",
    "            self._SD_calibrated.append(device+signal)\n",
    "            data_list = self._day_data[device]\n",
    "            for i, data_file in enumerate(data_list):\n",
    "                factor = data_file[signal].attrs['calibration_factor']\n",
    "                #print(factor)\n",
    "                data_file[signal][:] = (data_file[signal][:] * factor)\n",
    "                self._day_data[device][i] = data_file\n",
    "\n",
    "\n",
    "    def dict_read_signal(self, device, signal):\n",
    "        \"\"\"reads the signal of the corresponding device and writes it to the dictionary\"\"\"\n",
    "        files = self._day_data[device]\n",
    "        return {'signal': device+'_'+signal,\n",
    "                'attributes': list(map(lambda f: {'DC_offset': 0 if device == 'clear' else f[signal].attrs['removed_offset'],\n",
    "                              'calibration_factor': f[signal].attrs['calibration_factor'],\n",
    "                              'values': f[signal][:]\n",
    "                             }, files))\n",
    "\n",
    "               }\n",
    "\n",
    "    def center_and_calibrate(self, dict_signal):\n",
    "        \"\"\"reads the dictionary from the dict_read_signal() method, then centers and calibrates it\"\"\"\n",
    "        data_calibrated = {}\n",
    "        signal_data = dict_signal['attributes']\n",
    "        for data in signal_data:\n",
    "            data_calibrated[dict_signal['signal']] = ((data['values'] + data['DC_offset']) * data['calibration_factor']).astype(\"<f4\")\n",
    "\n",
    "        return data_calibrated\n",
    "##########################\n",
    "def get_time_diff(t1,t2):\n",
    "    t1_s = (t1.hour*60*60 + t1.minute*60 + t1.second)\n",
    "    t2_s = (t2.hour*60*60 + t2.minute*60 + t2.second)\n",
    "\n",
    "    delta_s = max([t1_s, t2_s]) - min([t1_s, t2_s])\n",
    "    return delta_s\n",
    "##########################\n",
    "blond = Blond(date(2016,10,5))\n",
    "\n",
    "\"\"\" Define a timeframe\"\"\"\n",
    "start_ts = time(0,50,0) # start_hours_minutes\n",
    "end_ts   = time(1,10,10)\n",
    "\n",
    "\"\"\"Read MEDAL and CLEAR data \"\"\"\n",
    "blond.read_files(start_ts, end_ts)\n",
    "\n",
    "\n",
    "\"\"\"Checking if files have been retrieved\"\"\"\n",
    "print(\"list the files:\")\n",
    "print(blond.list_files())\n",
    "\n",
    "##########################\n",
    "\"\"\"signals acquisited by MEDAL\"\"\"\n",
    "print(\"Files from Medal 1\")\n",
    "medal_file = blond.list_files()['medal-2'][0]\n",
    "print(type(medal_file[\"current1\"]))\n",
    "print([key for key in medal_file.keys()])\n",
    "##########################\n",
    "\"\"\"signals acquisited by CLEAR\"\"\"\n",
    "print(\"Keys from CLEAR\")\n",
    "clear_file = blond.list_files()['clear'][0]\n",
    "print([key for key in clear_file.keys()])\n",
    "##########################\n",
    "device = 'medal-2'\n",
    "signal = 'current1'\n",
    "\n",
    "\"\"\"Raw signal with offset and calibration factor attributes\"\"\"\n",
    "dict_signal = blond.dict_read_signal(device, signal)\n",
    "print(dict_signal)\n",
    "\n",
    "\n",
    "\"\"\"calibrated signal\"\"\"\n",
    "blond.center_and_calibrate(dict_signal)\n",
    "##########################\n",
    "\n",
    "def create_options():\n",
    "    seconds = get_time_diff(start_ts,end_ts)\n",
    "    minutes = int(seconds/60)\n",
    "    hours = int(minutes/60)\n",
    "\n",
    "    options={\n",
    "        \"duration\":[{\"label\":\"Duration in Seconds\", \"value\":\"None\"}]+ [{\"label\":str(i/10.0)+\" sec\",\"value\":i/10.0} for i in range(1,101)],\n",
    "        \"seconds\":[{\"label\":\"Start Second\", \"value\":\"None\"}]+[{\"label\":i,\"value\":i} for i in range(60)],\n",
    "        \"minutes\":[{\"label\":\"Start Minute\", \"value\":\"None\"}]+[{\"label\":i,\"value\":i} for i in range(60)],\n",
    "        \"hours\":[{\"label\":\"Start Hour\", \"value\":\"None\"}]+[{\"label\":i,\"value\":i} for i in range(start_ts.hour,end_ts.hour+1)],\n",
    "        \"critical\":{\n",
    "            \"start\":{\n",
    "                \"minutes\":[],\n",
    "                \"seconds\":[]\n",
    "            },\n",
    "            \"end\":{\n",
    "                \"minutes\":[],\n",
    "                \"seconds\":[]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if start_ts.hour != end_ts.hour:\n",
    "        options[\"critical\"][\"start\"][\"minutes\"] = [{\"label\":\"Start Minute\", \"value\":\"None\"}]+ [{\"label\":i,\"value\":i} for i in range(start_ts.minute,60)]\n",
    "        options[\"critical\"][\"end\"][\"minutes\"] = [{\"label\":\"Start Minute\", \"value\":\"None\"}]+ [{\"label\":i,\"value\":i} for i in range(0,end_ts.minute+1)]\n",
    "        if start_ts.minute != end_ts.minute:\n",
    "            options[\"critical\"][\"start\"][\"seconds\"] = [{\"label\":\"Start Second\", \"value\":\"None\"}]+[{\"label\":i,\"value\":i} for i in range(start_ts.second,60)]\n",
    "            options[\"critical\"][\"end\"][\"seconds\"] = [{\"label\":\"Start Second\", \"value\":\"None\"}]+[{\"label\":i,\"value\":i} for i in range(0,end_ts.second+1)]\n",
    "        else:\n",
    "            options[\"critical\"][\"start\"][\"seconds\"] = [{\"label\":\"Start Second\", \"value\":\"None\"}]+[{\"label\":i,\"value\":i} for i in range(start_ts.second,end_ts.second+1)]\n",
    "\n",
    "    else:\n",
    "        options[\"critical\"][\"start\"][\"minutes\"] = [{\"label\":\"Start Minute\", \"value\":\"None\"}]+[{\"label\":i,\"value\":i} for i in range(start_ts.minute,end_ts.minute+1)]\n",
    "        # in this case, hour values are same, we do not need critical end, because we will always see that, hour of time will always be equal to hour of start time\n",
    "\n",
    "    return options\n",
    "\n",
    "time_options = create_options()\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Data Reading and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blond = Blond(date(2016,10,5))\n",
    "\n",
    "\"\"\" Define a timeframe\"\"\"\n",
    "start_ts = time(6,17,50) # start_hours_minutes\n",
    "end_ts   = time(6,17,55)\n",
    "\n",
    "\"\"\"Read MEDAL and CLEAR data \"\"\"\n",
    "blond.read_files(start_ts, end_ts)\n",
    "\n",
    "\n",
    "\"\"\"Checking if files have been retrieved\"\"\"\n",
    "blond.list_files()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"signals acquisited by MEDAL\"\"\"\n",
    "medal_file = blond.list_files()['medal-1'][0]\n",
    "[key for key in medal_file.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"signals acquisited by CLEAR\"\"\"\n",
    "clear_file = blond.list_files()['clear'][0]\n",
    "[key for key in clear_file.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering and calibrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'medal-2'\n",
    "signal = 'current1'\n",
    "\n",
    "\"\"\"Raw signal with offset and calibration factor attributes\"\"\"\n",
    "dict_signal = blond.dict_read_signal(device, signal)\n",
    "print(dict_signal)\n",
    "\n",
    "\n",
    "\"\"\"calibrated signal\"\"\"\n",
    "blond.center_and_calibrate(dict_signal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to run dash app in jupyter:\n",
    "https://community.plot.ly/t/can-i-run-dash-app-in-jupyter/5235\n",
    "\"\"\"\n",
    "from IPython import display\n",
    "def show_app(app,  # type: dash.Dash\n",
    "             port=8050,\n",
    "             width=700,\n",
    "             height=350,\n",
    "             offline=True,\n",
    "             style=True,\n",
    "             **dash_flask_kwargs):\n",
    "    \"\"\"\n",
    "    Run the application inside a Jupyter notebook and show an iframe with it\n",
    "    :param app:\n",
    "    :param port:\n",
    "    :param width:\n",
    "    :param height:\n",
    "    :param offline:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    url = 'http://localhost:' + str(port)  + '/notebooks'\n",
    "    iframe = '<iframe src=\"{url}\" width={width} height={height}></iframe>'.format(url=url,\n",
    "                                                                                  width=width,\n",
    "                                                                                  height=height)\n",
    "    display.display_html(iframe, raw=True)\n",
    "    if offline:\n",
    "        app.css.config.serve_locally = True\n",
    "        app.scripts.config.serve_locally = True\n",
    "    if style:\n",
    "        external_css = [\"https://fonts.googleapis.com/css?family=Raleway:400,300,600\",\n",
    "                        \"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\",\n",
    "                        \"http://getbootstrap.com/dist/css/bootstrap.min.css\", ]\n",
    "\n",
    "        for css in external_css:\n",
    "            app.css.append_css({\"external_url\": css})\n",
    "\n",
    "        external_js = [\"https://code.jquery.com/jquery-3.2.1.min.js\",\n",
    "                       \"https://cdn.rawgit.com/plotly/dash-app-stylesheets/a3401de132a6d0b652ba11548736b1d1e80aa10d/dash-goldman-sachs-report-js.js\",\n",
    "                       \"http://getbootstrap.com/dist/js/bootstrap.min.js\"]\n",
    "\n",
    "        for js in external_js:\n",
    "            app.scripts.append_script({\"external_url\": js})\n",
    "\n",
    "    return app.run_server(debug=False,  # needs to be false in Jupyter\n",
    "                          port=port,\n",
    "                          **dash_flask_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Hello Dash'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Dash: A web application framework for Python.\n",
    "    '''),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='example-graph',\n",
    "        figure={\n",
    "            'data': [\n",
    "                {'x': [1, 2, 3], 'y': [4, 1, 5], 'type': 'line', 'name': 'SF'}\n",
    "            ],\n",
    "            'layout': {\n",
    "                'title': 'Dash Data Visualization'\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "show_app(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sps = 6400\n",
    "phase = 1\n",
    "requested_time = time(1,10,10)\n",
    "file_index = blond.find_corresponding_file(requested_time, blond.time_stamps['clear'])\n",
    "time_diff = get_time_diff(requested_time , blond.time_stamps['clear'][file_index])\n",
    "data_index_shift = time_diff * sps\n",
    "temp_data = blond.list_files()['clear'][file_index][\"current\"+str(phase)][data_index_shift:data_index_shift + int(sps*0.1)]\n",
    "\n",
    "curr_rms = []\n",
    "for curr in temp_data:\n",
    "    curr_rms.append(np.sqrt(np.mean(curr**2)))\n",
    "    \n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(18, 5))\n",
    "\n",
    "plot1 = ax[0]\n",
    "plot1.plot(temp_data, color='b', label='Current')\n",
    "plot1.plot(curr_rms, color='r', label='Period RMS of Current')\n",
    "plot1.set_title('Current of AC Electrolux')\n",
    "plot1.set_xlabel('Time [s]')\n",
    "plot1.set_ylabel('Current [A]')\n",
    "plot1.legend()\n",
    "\n",
    "plot2 = ax[1]\n",
    "plot2.plot(temp_data, color='b', label='Current')\n",
    "plot2.plot(curr_rms, color='r', label='Period RMS of Current')\n",
    "plot2.set_title('Waveform Comparison of AC Electrolux')\n",
    "plot2.set_xlabel('Time [ms]')\n",
    "plot2.legend()\n",
    "\n",
    "plot3 = ax[2]\n",
    "plot3.plot(temp_data, color='b', label='Current')\n",
    "plot3.plot(curr_rms, color='r', label='Period RMS of Current')\n",
    "plot3.set_title('Power over Time of AC Electrolux')\n",
    "plot3.set_xlabel('Time [s]')\n",
    "plot3.set_ylabel('Power [W]')\n",
    "plot3.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
